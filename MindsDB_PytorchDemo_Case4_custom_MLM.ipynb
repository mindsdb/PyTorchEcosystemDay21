{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accredited-settle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Datasource is not available by default. If you wish to use it, please install mindsdb_native[extra_data_sources]\n",
      "Athena Datasource is not available by default. If you wish to use it, please install mindsdb_native[extra_data_sources]\n",
      "Google Cloud Storage Datasource is not available by default. If you wish to use it, please install mindsdb_native[extra_data_sources]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING:mindsdb-logger-core-logger---:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/helpers/general_helpers.py:123 - There is a new version of MindsDB 2.40.0, please upgrade using:\n",
      "pip3 install mindsdb_native --upgrade\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning\n",
    "import torch\n",
    "import mindsdb_native as mdb\n",
    "\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "first-algeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f786481acd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup torch seed for reproducibility\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-delay",
   "metadata": {},
   "source": [
    "## 1) Load the dataset\n",
    "\n",
    "For simplicity in training (as the stanford dataset is quite large), we'll use a tripadvisor hotel review dataset.\n",
    "The goal of this dataset is to be able to predict the rating (1-5 stars, with 1 being the lowest and 5 being the highest) of the hotel, given an arbitary review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "female-boundary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mstanford_movie_review\u001b[0m/  \u001b[01;34mtripadvisor\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thrown-joshua",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10726</th>\n",
       "      <td>not recommend hotel did reviewers actually sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14919</th>\n",
       "      <td>barcelona rocks, stayed hotel jazz girlfriend ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>ok hotel good location stayed night way beijin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>great service nice pool ok beach lovely ground...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>surprising treat spent weekend july 15/16 2006...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Rating\n",
       "10726  not recommend hotel did reviewers actually sta...       1\n",
       "14919  barcelona rocks, stayed hotel jazz girlfriend ...       4\n",
       "19098  ok hotel good location stayed night way beijin...       3\n",
       "2450   great service nice pool ok beach lovely ground...       4\n",
       "960    surprising treat spent weekend july 15/16 2006...       5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"datasets/\"\n",
    "dataset = \"tripadvisor\"\n",
    "filename = os.path.join(data_dir, dataset, \"data.csv\")\n",
    "\n",
    "\n",
    "# Load the data, and scramble the order. The way the data has been \n",
    "data = pd.read_csv(filename).sample(frac=1, random_state=42)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-queen",
   "metadata": {},
   "source": [
    "We can see the polarity between a 5-star and 1-star rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "excellent-palestine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFive star (Label=5) Review:\n",
      "\u001b[0m surprising treat spent weekend july 15/16 2006 cartwright hotel based purely recommendations read site, actually expecting like small older european hotel, cartwright amazing, small elegant pleasant staff knowlegable city, room small nicely appointed queen bed linens quality, no airconditioning temperatures sf rarely warrant open windows fresh air night 4th floor, wine hour afternoon gave opportunity meet guests share days adventures breakfast buffet adequate, walk half block powell st cable car usually crowded stop, sf taxi cabs clean reasonably priced usually came built tour guide unlike cities english optional business, cartwright definitely hotel choice return san francisco,  \n",
      "\u001b[1m\n",
      "\n",
      "One star (Label=1) Review: \n",
      "\u001b[0m not recommend hotel did reviewers actually stay hotel did, good thing hotel location really close leidseplein, shared facilities filthy got, did not look toilet floor cleaned month, facilities not cleaned 3 days got, disgusting, staff rude complained left night early refused refund night, not recommend hotel,  \n"
     ]
    }
   ],
   "source": [
    "# Rating examples\n",
    "print(\"\\033[1m\" + \"Five star (Label=5) Review:\\n\" + \"\\033[0m\", data[data[\"Rating\"] == 5][\"Review\"].iloc[0])\n",
    "\n",
    "print(\"\\033[1m\" + \"\\n\\nOne star (Label=1) Review: \\n\" + \"\\033[0m\", data[data[\"Rating\"] == 1][\"Review\"].iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-missile",
   "metadata": {},
   "source": [
    "The ratings distribution is not equivalent; while we will use accuracy, we encourage considering other metrics to predict on such as precision, recall, and accuracy. For simplicity, we merely consider the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nonprofit-migration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ratings distribution')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# An example of the distribution of the model \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Distribution of the ratings\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,4))\n",
    "\n",
    "hist, bins = np.histogram(data[\"Rating\"], bins=np.arange(0.5, 6.5, 1))\n",
    "\n",
    "ax.bar(bins[:-1], hist.astype(np.float32) / hist.sum(), width=0.5)\n",
    "ax.set_xticks([i+0.5 for i in range(5)])\n",
    "ax.set_xticklabels([str(i+1) for i in range(5)])\n",
    "ax.set_yticks(np.arange(0, 0.55, 0.05))\n",
    "\n",
    "ax.set_xlabel(\"Ratings\")\n",
    "ax.set_ylabel(\"Percent of Dataset\")\n",
    "ax.set_title(\"Ratings distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-haiti",
   "metadata": {},
   "source": [
    "As indicated before, we will split our data into a training/testing branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "returning-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll split our training/testing fraction manually\n",
    "\n",
    "ptrain = 0.8\n",
    "Ntrain = int(data.shape[0] * ptrain)\n",
    "Ntest = int(data.shape[0] - Ntrain)\n",
    "\n",
    "train = data.iloc[:Ntrain, :]\n",
    "test = data.iloc[Ntrain:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-belief",
   "metadata": {},
   "source": [
    "## 2) Building your own custom encoder\n",
    "\n",
    "**NOTE: In order to run this encoder, you'll need at least 8GB of VRAM and a GPU. \n",
    "\n",
    "For our custom encoder, we will use a **masked language model** (MLM). To explain how an MLM works, imagine a sentence like this:\n",
    "\n",
    "\"This hotel is amazing! I loved my stay here, the bed was comfy and everything was perfect!\"\n",
    "\n",
    "We can convert this into a classification problem using MLM as such:\n",
    "\n",
    "\"Label is [MASK]. This hotel is amazing! I loved my stay here, the bed was comfy and everything was perfect!\"\n",
    "\n",
    "The goal would be to predict whether the hidden token is a positive or negative sentiment. To do this, we will construct \"placeholder\" tokens that represent the hidden label. The model then computes losses to try to predict what hidden token should replace the underlying label. The ground-truth label will be one of the placeholders we setup.\n",
    "\n",
    "**NOTE** While this technique is not necessarily recommended for classification (in fact, the fine-tuned approach, which is the default encoder of long-form text in MindsDB, tends to generally outperform the MLM strategy), we can still build our own custom encoder to leverage novel pytorch models with diverse loss functions and criteria.\n",
    "\n",
    "For convenience, we have provided 2 different scripts, `custom_encoder.py` and `mlm_helpers.py`. The `custom_encoder` script provides an example of how to build an MLM for classification, and `mlm_helpers`, as the name suggests, provides a few functions to help construct labels, new vocabulary, and train a model. \n",
    "\n",
    "We will show how to integrate this as a separate branch in the lightwood repo, and train with your own encoder of choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-allergy",
   "metadata": {},
   "source": [
    "### 2a) Making the custom encoder files \n",
    "\n",
    "The goal of the encoder is to learn a representation. Some encoders can be trained or \"tuned\" to generate a representation related to a particular label to ensure the representations contain useful information. In this simple example, we will tune the encoder with the target data.\n",
    "\n",
    "In this case, a representation is a feature vector that translates the \"data\" space into a format that is usable by a model. The term \"feature vector\", \"representation\", and \"embedding\" will be used interchangeably hence forth.\n",
    "\n",
    "![This is the caption\\label{mylabel}](images/fig1.png)\n",
    "*Figure 1: A representation will take an arbitrary sentence, like this hotel review, and convert it into some vector that a model can use. How the vector is constructed depends on the modeling of the language.*\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-practitioner",
   "metadata": {},
   "source": [
    "In the following example in ```custom_encoder.py``` we consider the ```MLMEncoder``` class. All base encoders require the following steps:\n",
    "\n",
    "(1) an ```__init__``` call used to instantitate the details of the encoder. The only required component of this call is to ensure that the encoder knows whether you are tuning the embeddings to the target or not.  \n",
    "\n",
    "(2) A ```prepare``` call; This sets up the preliminary ground work of tokenizing and training the encoder to the representation of interest. You can think of this as the ***feature extraction step***\n",
    "\n",
    "(3) An ```encode``` command; this creates a representation/embedding that will be provided downstream to the mixer or predictive model of the piepline .\n",
    "\n",
    "(4) A ```decode``` step; This steps translated the featurized form back into the original space. For text, we implemented an Exception, as decoding will be tricky (as an aside -one possible option is to decode back into the tokenized space for language generation!)\n",
    "\n",
    "(5) A ```to``` step; this step enables you to set the model to a different device (CPU/CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-argentina",
   "metadata": {},
   "source": [
    "For specific highlights of the custom encoder, see the script available. As a high level overview:\n",
    "\n",
    "1) The prepare step calls the ```DistilBertForMaskedLanguageModeling``` model and ```DistilBertTokenizerFast``` for the model and tokenizer respectively  \n",
    "\n",
    "2) It prepares a priming sentence with a \"[MASK]\" to be predicted, with the help of ```mlm_helpers``` functions.  \n",
    "\n",
    "3) For each label, it creates a new token \"[Ci]\" where $i$ represents the label number and resizes it to the tokenizer and the model embedding dimensionality. The goal of the model is to predict which token must appear under the Mask.\n",
    "\n",
    "4) It trains the MLM to predict the mask from the underlying label for 1 epoch (default)  \n",
    "\n",
    "5) The encoder creates an embedding by predicting what the underlying mask token is, replacing it in the model input, and then calculating the last hidden-state of the base DistilBert model and presenting the \"[CLS]\" token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-unemployment",
   "metadata": {},
   "source": [
    "In order to integrate these changes and run our custom encoder, we need to make some changes to the lightwood repo. Clone your own lightwood repo [here](https://github.com/mindsdb/lightwood). You can use the command ```python setup.py install --user``` to install from the local source.\n",
    "\n",
    "Make a new branch from the stable by the following command:\n",
    "\n",
    "```git checkout -b my_branch_name``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-storage",
   "metadata": {},
   "source": [
    "Now to make your own changes: In ```lightwood/encoders/text``` place your ```custom_encoders.py``` script.\n",
    "\n",
    "Subsequently, for your helpers file, place it in ```lightwood/encoders/text/helpers```\n",
    "\n",
    "![This is the caption\\label{mylabel}](images/fig2.png)\n",
    "<br>\n",
    "*Figure 2: An example of where the files should be*\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-momentum",
   "metadata": {},
   "source": [
    "Now, we need to provide references for lightwood to access these encoders. Change the ```__init__.py``` file in ```lightwood/encoders/text/``` and import your encoder\n",
    "\n",
    "![This is the caption\\label{mylabel}](images/fig33.png)\n",
    "<br>\n",
    "*Figure 3: Import the MLM encoder to the very bottom of this file*\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-pregnancy",
   "metadata": {},
   "source": [
    "Last step, we need ensure that text data will be read as this type of encoder. To do so, we'll make one more change. To do this, we will change the ```data_source.py``` file; this is the file that infers what encoder to use, given a particular column type.\n",
    "\n",
    "In order to do this, go to ```lightwood/api/data_source.py``` and add 2 lines: (a) import your encoder in the beginning of this file and (b) change ```__lookup_encoder_class``` by introducing ```ColumnDataTypes.TEXT: MLMEncoder``` instead of the default, ```PretrainedLang```. This will now enable you to use your custom encoder into the model.\n",
    "\n",
    "![This is the caption\\label{mylabel}](images/fig4.png)\n",
    "<br>\n",
    "*Figure 4: Import the MLM Encoder from lightwood's encoders *\n",
    "<br>\n",
    "\n",
    "\n",
    "![This is the caption\\label{mylabel}](images/fig5.png)\n",
    "<br>\n",
    "*Figure 5: Ensure the text column type for text now defaults to our MLM Encoder* \n",
    "<br>\n",
    "\n",
    "To make this simple, we provided 2 repositories to test between these steps. You can ```git checkout default_textenc``` for our default version, or ```git checkout mlm``` for the masked language model implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-found",
   "metadata": {},
   "source": [
    "## 3) Testing your new encoder out!\n",
    "\n",
    "Using a git command to switch between repos, we can test how the baseline model performs compared to our new version.\n",
    "\n",
    "Note, the branches we provide are `default_textenc` and `mlm`; you can swap between these two lightwood repos and see how your model fares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "confidential-illinois",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING:mindsdb-logger-core-logger---:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/helpers/general_helpers.py:123 - There is a new version of MindsDB 2.40.0, please upgrade using:\n",
      "pip3 install mindsdb_native --upgrade\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/controllers/predictor.py:211 - Sample for analysis: True\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:51 - [START] DataExtractor\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:56 - [END] DataExtractor, execution time: 0.035 seconds\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:51 - [START] DataCleaner\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:56 - [END] DataCleaner, execution time: 0.045 seconds\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:51 - [START] TypeDeductor\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/type_deductor/type_deductor.py:301 - Analyzing a sample of 8947 from a total population of 16392, this is equivalent to 54.6% of your data.\n",
      "\u001b[0m\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/natasha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/type_deductor/type_deductor.py:393 - Data distribution for column \"Review\" of type \"Categorical\" and subtype \"Category\"\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/data_types/mindsdb_logger.py:81 - ----------\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/data_types/mindsdb_logger.py:124 -  Category: 8947\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/data_types/mindsdb_logger.py:128 - ----------\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/type_deductor/type_deductor.py:393 - Data distribution for column \"Rating\" of type \"Categorical\" and subtype \"Category\"\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/data_types/mindsdb_logger.py:81 - ----------\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/data_types/mindsdb_logger.py:124 -  Category: 8947\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/data_types/mindsdb_logger.py:128 - ----------\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:56 - [END] TypeDeductor, execution time: 59.571 seconds\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:51 - [START] DataAnalyzer\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/data_analyzer/data_analyzer.py:253 - Analyzing a sample of 8947 from a total population of 16392, this is equivalent to 54.6% of your data.\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/data_analyzer/data_analyzer.py:265 - Analyzing column: Review !\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/data_analyzer/data_analyzer.py:323 - You may want to check if you see something suspicious on the right-hand-side graph. This doesn't necessarily mean there's an issue with your data, it just indicates a higher than usual probability there might be some issue.\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/data_analyzer/data_analyzer.py:343 - Finished analyzing column: Review !\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/data_analyzer/data_analyzer.py:265 - Analyzing column: Rating !\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/data_analyzer/data_analyzer.py:343 - Finished analyzing column: Rating !\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:56 - [END] DataAnalyzer, execution time: 0.315 seconds\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:51 - [START] DataCleaner\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:56 - [END] DataCleaner, execution time: 0.041 seconds\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:51 - [START] DataSplitter\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/data_splitter/data_splitter.py:109 - We have split the input data into:\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:56 - [END] DataSplitter, execution time: 0.842 seconds\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:51 - [START] DataTransformer\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:56 - [END] DataTransformer, execution time: 0.030 seconds\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:51 - [START] ModelInterface\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natasha/mdb/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/natasha/mdb/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "INFO:root:A single GBM itteration takes 0.1 seconds\n",
      "INFO:root:Training GBM (<module 'optuna.integration.lightgbm' from '/home/natasha/mdb/lib/python3.8/site-packages/optuna/integration/lightgbm.py'>) with 100 iterations\n",
      "feature_fraction, val_score: 0.960688: 100%|##########| 7/7 [03:46<00:00, 32.33s/it]\n",
      "num_leaves, val_score: 0.947608: 100%|##########| 20/20 [17:07<00:00, 51.35s/it]\n",
      "bagging, val_score: 0.947569: 100%|##########| 10/10 [04:51<00:00, 29.19s/it]\n",
      "feature_fraction_stage2, val_score: 0.947569: 100%|##########| 6/6 [02:15<00:00, 22.59s/it]\n",
      "regularization_factors, val_score: 0.945650: 100%|##########| 20/20 [07:30<00:00, 22.52s/it]\n",
      "min_data_in_leaf, val_score: 0.943244: 100%|##########| 5/5 [01:47<00:00, 21.40s/it]\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:454 - [LightGBMMixer] Training accuracy of: {'Rating': {'function': 'accuracy_score', 'value': 0.49521404387240714}}\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Computing device used: cuda\n",
      "INFO:lightwood.3239:Computing device used: cuda\n",
      "INFO:lightwood.3239:Building network of shape: [768, 65, 6]\n",
      "INFO:lightwood.3239:Subtest test error: 1.6075451374053955 on subset 1, overall test error: 1.6007304059134588\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 0 with an accuracy of 34.38% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 1.0571844577789307 on subset 1, overall test error: 1.0752058956358168\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 38 with an accuracy of 52.53% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 1.0040361086527507 on subset 1, overall test error: 1.0338060723410711\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 76 with an accuracy of 52.79% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 0.9978542923927307 on subset 1, overall test error: 1.033229841126336\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 114 with an accuracy of 53.16% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 0.9909699161847433 on subset 1, overall test error: 1.0401667025354173\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 152 with an accuracy of 53.88% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 1.02169930934906 on subset 1, overall test error: 1.066288987795512\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 190 with an accuracy of 53.66% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 1.0502528349558513 on subset 1, overall test error: 1.1009883019659255\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 228 with an accuracy of 53.24% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 1.0604734023412068 on subset 1, overall test error: 1.1344810922940571\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 266 with an accuracy of 52.36% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Finished fitting on 1 of 3 subset\n",
      "INFO:lightwood.3239:Subtest test error: 0.9969945748647054 on subset 2, overall test error: 1.0284285479121738\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 0 with an accuracy of 54.3% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 0.9930976629257202 on subset 2, overall test error: 1.0127944813834295\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 38 with an accuracy of 55.09% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 1.0304004549980164 on subset 2, overall test error: 1.0419155293040805\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 76 with an accuracy of 54.31% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 1.0475206573804219 on subset 2, overall test error: 1.0503032406171162\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 114 with an accuracy of 53.47% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 1.0830657482147217 on subset 2, overall test error: 1.0793113907178242\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 152 with an accuracy of 52.35% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 1.1287591457366943 on subset 2, overall test error: 1.1193056371476915\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 190 with an accuracy of 52.37% on the testing dataset\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightwood.3239:Finished fitting on 2 of 3 subset\n",
      "INFO:lightwood.3239:Subtest test error: 1.0920781095822651 on subset 3, overall test error: 1.013155738512675\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 0 with an accuracy of 55.41% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 1.0927695830663045 on subset 3, overall test error: 1.0170532663663228\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 38 with an accuracy of 54.71% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Lightwood training, iteration 62, training error 0.9379810338670557\n",
      "INFO:lightwood.3239:Subtest test error: 1.097238798936208 on subset 3, overall test error: 1.0182354781362746\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 76 with an accuracy of 56.12% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 1.1310274998346965 on subset 3, overall test error: 1.037471055984497\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 114 with an accuracy of 53.05% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 1.1530222495396931 on subset 3, overall test error: 1.0604393018616571\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 152 with an accuracy of 54.55% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Subtest test error: 1.191910187403361 on subset 3, overall test error: 1.0825219816631741\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[37mDEBUG:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:328 - We've reached training epoch nr 190 with an accuracy of 54.0% on the testing dataset\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Finished fitting on 3 of 3 subset\n",
      "INFO:lightwood.3239:Finished training model !\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/model_interface/lightwood_backend.py:454 - [NnMixer] Training accuracy of: {'Rating': {'function': 'accuracy_score', 'value': 0.5541134074915297}}\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Computing device used: cuda\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:56 - [END] ModelInterface, execution time: 2514.779 seconds\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:51 - [START] ModelAnalyzer\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Computing device used: cuda\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "INFO:lightwood.3239:Computing device used: cuda\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "INFO:lightwood.3239:Computing device used: cuda\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "INFO:lightwood.3239:Computing device used: cuda\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "INFO:lightwood.3239:Computing device used: cuda\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[32mINFO:mindsdb-logger-52b72b30-a229-11eb-a0cc-c99caea855db---51d83821-9541-4234-bb11-6859bb465cbd:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:56 - [END] ModelAnalyzer, execution time: 245.765 seconds\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create a predictor instance\n",
    "model = mdb.Predictor(name=\"text_reviews\")\n",
    "\n",
    "# Train your model!\n",
    "model.learn(from_data=train, to_predict=\"Rating\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opened-throw",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:mindsdb-logger-core-logger---:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:51 - [START] DataExtractor\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-core-logger---:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:56 - [END] DataExtractor, execution time: 0.016 seconds\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-core-logger---:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:51 - [START] DataTransformer\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-core-logger---:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:56 - [END] DataTransformer, execution time: 0.010 seconds\n",
      "\u001b[0m\n",
      "\u001b[32mINFO:mindsdb-logger-core-logger---:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:51 - [START] ModelInterface\n",
      "\u001b[0m\n",
      "INFO:lightwood.3239:Computing device used: cuda\n",
      "INFO:lightwood.3239:Model predictions and decoding completed\n",
      "\u001b[32mINFO:mindsdb-logger-core-logger---:/home/natasha/mdb/lib/python3.8/site-packages/mindsdb_native/libs/phases/base_module.py:56 - [END] ModelInterface, execution time: 53.620 seconds\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "endangered-combat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is = 0.565747743352037\n"
     ]
    }
   ],
   "source": [
    "ypred = result._data[\"Rating\"]\n",
    "ytrue = test[\"Rating\"].astype(str).tolist()\n",
    "\n",
    "acc = [ypred[j] == ytrue[j] for j in range(len(ypred))]\n",
    "\n",
    "print(\"Accuracy is =\", sum(acc)/len(acc))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "built-silly",
   "metadata": {},
   "source": [
    "For our new MLM encoder, we anticipate an accuracy of around 0.566; for our default encoder provided, you can anticipate it to be around 0.644.\n",
    "\n",
    "We are currently working on a feature to enable users to quickly modify encoders by simply flagging their custom encoders through a configuration file! Stay tuned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdb",
   "language": "python",
   "name": "mdb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
